{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5984b0af-1e1f-43a6-ab14-96e0fd66d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f17073-280b-4a71-a320-2d5777463655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import logging\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import schedule\n",
    "import warnings\n",
    "# Suppress only DeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from model_pipeline import model_pipeline\n",
    "\n",
    "class S3BucketHandler(FileSystemEventHandler):\n",
    "    def __init__(self, credentials_file='.env'):\n",
    "        self.credentials_file = credentials_file\n",
    "        self.bucket_name = \"scetru-ml-bucket\"\n",
    "        self.s3 = self._load_credentials()\n",
    "        self.last_contents = set()\n",
    "        self.new_csv_files = [] #empty list to hold new files detected.\n",
    "\n",
    "    def _load_credentials(self):\n",
    "        load_dotenv(self.credentials_file)\n",
    "        access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "        return boto3.client('s3', aws_access_key_id=access_key_id, aws_secret_access_key=secret_access_key)\n",
    "\n",
    "    def on_any_event(self, event):\n",
    "        column_types = {\n",
    "            'bvn': 'str',\n",
    "            'application_id': 'str',\n",
    "            'amount_requested': 'float',\n",
    "            'date_created': 'date',\n",
    "            'airtime_in_90days': 'float',\n",
    "            'bill_payment_in_90days': 'float',\n",
    "            'cable_tv_in_90days': 'float',\n",
    "            'deposit_in_90days': 'float',\n",
    "            'easy_payment_in_90days': 'float',\n",
    "            'farmer_in_90days': 'float',\n",
    "            'inter_bank_in_90days': 'float',\n",
    "            'mobile_in_90days': 'float',\n",
    "            'utility_bills_in_90days': 'float',\n",
    "            'withdrawal_in_90days': 'float',\n",
    "            }\n",
    "        \n",
    "        required_columns = list(column_types.keys())\n",
    "        #bucket_name = \"scetru-ml-bucket\"\n",
    "        \n",
    "        try:\n",
    "            current_contents = set(self._list_bucket_contents(self.bucket_name))\n",
    "            new_files = current_contents - self.last_contents\n",
    "            \n",
    "            for file in new_files:\n",
    "                if file.endswith('.csv'):\n",
    "                    #### logging.info(f\"Alert: New .csv file detected in bucket {self.bucket_name}: {file}\")\n",
    "                    df = self._read_csv_from_s3(self.bucket_name, file)\n",
    "                        \n",
    "                    # Check for required columns\n",
    "                    missing_columns = set(required_columns) - set(df.columns)\n",
    "                    if missing_columns:\n",
    "                        print(f\"Missing required columns in {file}: {missing_columns}\")\n",
    "                    else:\n",
    "                        self.new_csv_files.append(df)\n",
    "                        #### logging.info(f\"All required columns present in {file}\")                         \n",
    "      \n",
    "            self.last_contents = current_contents #set the last state of the bucket.\n",
    "\n",
    "            # Merge dataframes if multiple new CSV files were detected\n",
    "            while self.new_csv_files: \n",
    "                trans_data = pd.concat(self.new_csv_files, ignore_index=True) \n",
    "                trans_data = trans_data[required_columns]\n",
    "                trans_data = trans_data[~trans_data['application_id'].isnull()] # excluded records where application_id is null\n",
    "                trans_data.reset_index(drop=True, inplace=True)\n",
    "                # convert columns to the right data types\n",
    "                trans_data = S3BucketHandler.convert_columns_type(trans_data, column_types)\n",
    "                trans_data = trans_data.drop_duplicates()\n",
    "                trans_data.fillna(0.0, inplace=True)\n",
    "                \n",
    "                # merge trans_data with do_good_table\n",
    "                merged_df = self.join_trans_with_do_good(trans_data)\n",
    "                model_outcome = model_pipeline(merged_df)\n",
    "                # logging.info(f\"Parsed the merged DataFrame to model pipeline\")\n",
    "                \n",
    "                # read and update the complete_table\n",
    "                complete_table_ = self.read_and_create_complete_table(model_outcome)\n",
    "\n",
    "                if not complete_table_.empty:\n",
    "                    complete_table_.to_csv(\"complete_table.csv\", index=False)\n",
    "\n",
    "                    S3BucketHandler.saved_processed_df_as_csv(complete_table_) # save for audit\n",
    "                    # upload the complete table\n",
    "           \n",
    "                    self.upload_files_to_s3_bucket(\n",
    "                            local_filepath = \"processed_loan_request\", \n",
    "                            bucket_name = \"complete-table\" ,\n",
    "                            s3_path_prefix = complete_table_.file_key.iloc[0].split('/')[0],\n",
    "                            files_to_upload = [str(i) for i in complete_table_.application_id])\n",
    "                \n",
    "                else:\n",
    "                    print(\"No records in complete table, continuing to watch for new files.\")\n",
    "                \n",
    "                # Clear the list of new CSV files\n",
    "                self.new_csv_files.clear()\n",
    "                 \n",
    "        except ClientError as e:\n",
    "            print(f\"Error accessing S3 bucket: {e}\")\n",
    "\n",
    "    def _list_bucket_contents(self, bucket_name):\n",
    "        try:\n",
    "            response = self.s3.list_objects_v2(Bucket=bucket_name)\n",
    "            return [obj['Key'] for obj in response.get('Contents', [])]\n",
    "        except ClientError as e:\n",
    "            # Handle bucket not found error here (e.response['Error']['Code'] == 'NoSuchBucket')\n",
    "            #### logging.error(f\"Bucket {self.bucket_name} does not exist or access denied: {e}\")\n",
    "            return []  # Return an empty list to avoid further errors\n",
    "\n",
    "    def _read_csv_from_s3(self, bucket_name, file_key):\n",
    "        obj = self.s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        df = pd.read_csv(obj['Body'])\n",
    "        df['file_key'] = file_key  # Add file_key as a new column\n",
    "        return df\n",
    "        \n",
    "    def join_trans_with_do_good(self, trans_data):\n",
    "        do_good_table = self.collate_file(\"scetru-fcmb-do-good-table\")\n",
    "        columns_ = ['bvn', 'applicationID', 'date_of_default', 'outstanding_balance']\n",
    "        do_good_table = do_good_table[columns_]\n",
    "        do_good_table['bvn'] = do_good_table['bvn'].astype(str)\n",
    "\n",
    "        merged_df = trans_data.merge(do_good_table, on='bvn', how='left')\n",
    "        merged_df['date_of_default'] = pd.to_datetime(merged_df['date_of_default'], errors='coerce')\n",
    "        current_date = pd.Timestamp.now()\n",
    "        merged_df['default_in_last_90days'] = np.where(\n",
    "            ((current_date - merged_df['date_of_default']).dt.days <= 90) & (merged_df['outstanding_balance'] != 0), \n",
    "            'Y', \n",
    "            'N'\n",
    "        )\n",
    "        merged_df['has_it_make_it_good'] = np.where(\n",
    "            (merged_df['outstanding_balance'] == 0) | (merged_df['default_in_last_90days'] == 'N'), \n",
    "            'Y', \n",
    "            'N'\n",
    "        )\n",
    "        \n",
    "        merged_df.drop(columns=['date_of_default', 'outstanding_balance', 'applicationID'], inplace=True)\n",
    "        return merged_df\n",
    "\n",
    "    def read_and_create_complete_table(self, outcome_table):\n",
    "        # Read and create complete table\n",
    "        complete_table = self.collate_file(\"complete-table\")\n",
    "        complete_table.replace(r'^\\s*$', np.nan, regex=True, inplace=True) # fill missing column with Nan\n",
    "        complete_table['application_id'] = complete_table['application_id'].astype(str)\n",
    "        complete_table['bvn'] = complete_table['bvn'].astype(str)\n",
    "        # Excluding transactions previously processed by ml services or streaming process.\n",
    "        complete_table = complete_table[(complete_table['decline_reason'].isnull()) & (complete_table['amount_approved'].isnull())].reset_index(drop=True)\n",
    "        complete_table = complete_table.drop(columns=['amount_approved', 'decline_reason'])\n",
    "        create_complete_table = complete_table.merge(outcome_table[outcome_table['application_id'].isin(complete_table['application_id'].unique())][['bvn', 'application_id', 'amount_approved','decline_reason']],\n",
    "                               on=['bvn', 'application_id'], how='inner', suffixes=('', '_outcome'))\n",
    "\n",
    "        # Add new columns and reorder (consider using pipe syntax)\n",
    "        create_complete_table['updated_date'] = pd.Timestamp.now().floor('min')\n",
    "        create_complete_table['loan_message'] = 'COMPLETED'\n",
    "        create_complete_table = create_complete_table[['bvn', 'dob', 'amount_requested', 'application_id', 'loan_tenure','loan_repayment_structure',\n",
    "                              'internal_id', 'amount_approved','created_date', 'updated_date', 'decline_reason', 'loan_message',\n",
    "                              'file_key']]\n",
    "        return create_complete_table\n",
    "\n",
    "    def collate_file(self, bucket_name):\n",
    "        new_files = []\n",
    "        files = set(self._list_bucket_contents(bucket_name))\n",
    "        for file in files:\n",
    "            df = self._read_csv_from_s3(bucket_name, file)\n",
    "            new_files.append(df)\n",
    "\n",
    "        collated_files = pd.concat(new_files, ignore_index=True)\n",
    "        return collated_files\n",
    "\n",
    "    \n",
    "    def upload_files_to_s3_bucket(self, local_filepath, bucket_name, s3_path_prefix='', files_to_upload=None):\n",
    "        \"\"\"\n",
    "        Uploads all CSV files from a folder to an S3 bucket.\n",
    "        \n",
    "        Args:\n",
    "            local_filepath (str): Path to the folder containing CSV files.\n",
    "            bucket_name (str): Name of the S3 bucket to upload the files to.\n",
    "            s3_path_prefix (str, optional): Prefix to add to the S3 file paths. Defaults to an empty string.\n",
    "            files_to_upload (list, optional): List of filenames without extension to upload. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # Filter for CSV files to upload\n",
    "        csv_files = [file for file in os.listdir(local_filepath) if file.endswith('.csv') \n",
    "                     and (files_to_upload is None or os.path.splitext(file)[0] \n",
    "                          in files_to_upload)\n",
    "                    ]\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(f\"No CSV files found in {local_filepath}.\")\n",
    "            return\n",
    "        \n",
    "        for filename in csv_files:\n",
    "            local_file = os.path.join(local_filepath, filename)\n",
    "            s3_file = f\"{s3_path_prefix}/{filename}\" if s3_path_prefix else filename\n",
    "\n",
    "            try:\n",
    "                self.s3.upload_file(local_file, bucket_name, s3_file)\n",
    "                print(f\"Upload Successful: from {local_file} to s3://{bucket_name}/{s3_file}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"The file {local_file} was not found\")\n",
    "            except NoCredentialsError:\n",
    "                print(\"Credentials not available\")\n",
    "\n",
    "    \n",
    "    def clean_ml_bucket(self):\n",
    "        \"\"\"\n",
    "        Deletes all files from the S3 bucket.\n",
    "        \"\"\"\n",
    "        files_to_delete = self._list_bucket_contents(self.bucket_name)\n",
    "        \n",
    "        if files_to_delete:\n",
    "            delete_objects = {'Objects': [{'Key': key} for key in files_to_delete]}\n",
    "            try:\n",
    "                self.s3.delete_objects(Bucket=self.bucket_name, Delete=delete_objects)\n",
    "                print(f\"Deleted {len(files_to_delete)} .csv files from {self.bucket_name}\")\n",
    "            except ClientError as e:\n",
    "                print(f\"An error occurred while deleting objects: {e}\")\n",
    "        else:\n",
    "            print(\"No files found in the bucket\")\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def convert_columns_type(df, column_types):\n",
    "        \"\"\"\n",
    "        Converts columns in the DataFrame to the specified data types.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to be converted.\n",
    "        column_types (dict): A dictionary where keys are column names and values are the desired data types.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: The DataFrame with converted columns.\n",
    "        \"\"\"\n",
    "        for col, dtype in column_types.items():\n",
    "            if col in df.columns:\n",
    "                if dtype == 'date':\n",
    "                    df[col] = pd.to_datetime(df[col]).dt.date\n",
    "                else:\n",
    "                    df[col] = df[col].astype(dtype)\n",
    "            else:\n",
    "                print(f\"Warning: Column '{col}' does not exist in the DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def saved_processed_df_as_csv(df_outcome):\n",
    "        if len(df_outcome) > 0:\n",
    "            # Ensure the directory to save the files exists\n",
    "            output_dir = 'processed_loan_request' #staging area\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "            # Iterate over each unique application_id and save records to separate CSV files\n",
    "            for application_id, group in df_outcome.groupby('application_id'):\n",
    "                # Define the file path locally\n",
    "                local_file_path = os.path.join(output_dir, f\"{application_id}.csv\")\n",
    "    \n",
    "                # Save the group to a CSV file\n",
    "                group.to_csv(local_file_path, index=False)\n",
    "    \n",
    "            print(\"Files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf66832-a008-4b26-ac69-3ee7eaff57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_s3_bucket(interval=1):\n",
    "    handler = S3BucketHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(handler, path='.', recursive=False)\n",
    "\n",
    "    # Schedule the clean_ml_bucket method to run at midnight \n",
    "    schedule.every().day.at(\"00:00\").do(handler.clean_ml_bucket)\n",
    "\n",
    "    try:\n",
    "        # Check bucket existence and credential validity before starting monitoring\n",
    "        if not handler._list_bucket_contents(handler.bucket_name):\n",
    "            #### logging.error(f\"Bucket {bucket_name} does not exist or access denied.\")\n",
    "            return\n",
    "\n",
    "        #### logging.info(f\"Bucket {bucket_name} exists and access successful. Starting monitoring.\")\n",
    "        observer.start()\n",
    "        \n",
    "        while True:\n",
    "            schedule.run_pending() # Run scheduled tasks\n",
    "            time.sleep(interval)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ccc1ab-37b4-44e3-a139-6fb53b1df246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 2 .csv files from scetru-ml-bucket\n"
     ]
    }
   ],
   "source": [
    "monitor_s3_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c80d4ab3-19c0-483f-a7b2-ab4fa4337a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload return_complete_table\n",
    "# archive the bucket_data\n",
    "# clean bucket at midnight after 3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf85ee8-501d-4f65-823a-30aa88750f88",
   "metadata": {},
   "source": [
    "#### TEST THE UPDATED COMPLETED TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c814c-65c7-4192-9ae3-b506d795fc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caadc98-7a4f-439b-8ac3-f6717f589f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update comeplete table\n",
    "handler = S3BucketHandler()\n",
    "local_filepath = \"processed_loan_request\", \n",
    "bucket_name = \"complete-table\" ,\n",
    "s3_path_prefix = return_complete_table.file_key.iloc[0].split('/')[0],\n",
    "files_to_upload = [str(i) for i in return_complete_table.application_id])\n",
    "\n",
    "handler.load_files_to_s3_bucket(self, local_filepath, bucket_name, s3_path_prefix='', files_to_upload=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc52a2-4505-44e7-b1fb-0834199088ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d9c891-9388-4ea0-9921-51d8aac9f171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bvn</th>\n",
       "      <th>dob</th>\n",
       "      <th>amount_requested</th>\n",
       "      <th>application_id</th>\n",
       "      <th>loan_tenure</th>\n",
       "      <th>loan_repayment_structure</th>\n",
       "      <th>internal_id</th>\n",
       "      <th>amount_approved</th>\n",
       "      <th>created_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>decline_reason</th>\n",
       "      <th>loan_message</th>\n",
       "      <th>file_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22207845921</td>\n",
       "      <td>28-01-1998</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>7564669779</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-3a2ebb25-9ada-47d7-ba78-4faa79ebba42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-26 21:28</td>\n",
       "      <td>2024-11-28 10:31:00</td>\n",
       "      <td>Loan declined due to low transaction or incomp...</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>fcmb_20241126/7564669779.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22150969042</td>\n",
       "      <td>02-01-2008</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>253435676</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-4d9471aa-7ea1-4234-8b2e-5313f0103e54</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2024-08-02 16:26</td>\n",
       "      <td>2024-08-02 17:26:00</td>\n",
       "      <td></td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>fcmb_20240802/253435676.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22207845921</td>\n",
       "      <td>26-08-2024</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>7564669779</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-50b7f803-5ce4-42c4-871e-dd07278f824f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-08-28 15:41</td>\n",
       "      <td>2024-11-01 10:26:00</td>\n",
       "      <td>Loan declined due to low transaction or incomp...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>fcmb_20240828/7564669779.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22377535967</td>\n",
       "      <td>02-02-2013</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>54682632</td>\n",
       "      <td>1 year</td>\n",
       "      <td>biweekly</td>\n",
       "      <td>sce-de4dd6b7-2479-495f-aa02-49982e97d560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-02 16:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer does not have enough transactions</td>\n",
       "      <td>DECLINED</td>\n",
       "      <td>fcmb_20240802/54682632.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22150969042</td>\n",
       "      <td>30-12-1998</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>156748766</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-4a0e8bc7-d2d8-4388-b766-219f51bc041a</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2024-11-26 21:27</td>\n",
       "      <td>2024-11-28 10:31:00</td>\n",
       "      <td></td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>fcmb_20241126/156748766.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22150969042</td>\n",
       "      <td>21-01-1996</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>156748766</td>\n",
       "      <td>1 year</td>\n",
       "      <td>biweekly</td>\n",
       "      <td>sce-cefe9f56-242c-4c2d-9d66-7441946edc5c</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2024-11-28 11:30</td>\n",
       "      <td>2024-11-28 11:38:00</td>\n",
       "      <td></td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>fcmb_20241128/156748766.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bvn         dob  amount_requested  application_id loan_tenure  \\\n",
       "0  22207845921  28-01-1998          670000.0      7564669779      1 year   \n",
       "1  22150969042  02-01-2008           67000.0       253435676      1 year   \n",
       "2  22207845921  26-08-2024          340000.0      7564669779      1 year   \n",
       "3  22377535967  02-02-2013           45000.0        54682632      1 year   \n",
       "4  22150969042  30-12-1998          340000.0       156748766      1 year   \n",
       "5  22150969042  21-01-1996          450000.0       156748766      1 year   \n",
       "\n",
       "  loan_repayment_structure                               internal_id  \\\n",
       "0                  monthly  sce-3a2ebb25-9ada-47d7-ba78-4faa79ebba42   \n",
       "1                  monthly  sce-4d9471aa-7ea1-4234-8b2e-5313f0103e54   \n",
       "2                  monthly  sce-50b7f803-5ce4-42c4-871e-dd07278f824f   \n",
       "3                 biweekly  sce-de4dd6b7-2479-495f-aa02-49982e97d560   \n",
       "4                  monthly  sce-4a0e8bc7-d2d8-4388-b766-219f51bc041a   \n",
       "5                 biweekly  sce-cefe9f56-242c-4c2d-9d66-7441946edc5c   \n",
       "\n",
       "   amount_approved      created_date         updated_date  \\\n",
       "0              0.0  2024-11-26 21:28  2024-11-28 10:31:00   \n",
       "1          90000.0  2024-08-02 16:26  2024-08-02 17:26:00   \n",
       "2              0.0  2024-08-28 15:41  2024-11-01 10:26:00   \n",
       "3              NaN  2024-08-02 16:32                  NaN   \n",
       "4          90000.0  2024-11-26 21:27  2024-11-28 10:31:00   \n",
       "5          90000.0  2024-11-28 11:30  2024-11-28 11:38:00   \n",
       "\n",
       "                                      decline_reason loan_message  \\\n",
       "0  Loan declined due to low transaction or incomp...    COMPLETED   \n",
       "1                                                       COMPLETED   \n",
       "2  Loan declined due to low transaction or incomp...    Completed   \n",
       "3         Customer does not have enough transactions     DECLINED   \n",
       "4                                                       COMPLETED   \n",
       "5                                                       COMPLETED   \n",
       "\n",
       "                       file_key  \n",
       "0  fcmb_20241126/7564669779.csv  \n",
       "1   fcmb_20240802/253435676.csv  \n",
       "2  fcmb_20240828/7564669779.csv  \n",
       "3    fcmb_20240802/54682632.csv  \n",
       "4   fcmb_20241126/156748766.csv  \n",
       "5   fcmb_20241128/156748766.csv  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## update comeplete table\n",
    "handler = S3BucketHandler()\n",
    "complete_ = handler.collate_file(\"complete-table\")\n",
    "#result = complete_[complete_['loan_message'] == 'IN PROGRESS']\n",
    "#result.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "#result\n",
    "complete_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "239d626e-b3d8-45a9-a771-5668948b7f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fcmb_20240802/253435676.csv',\n",
       " 'fcmb_20240802/54682632.csv',\n",
       " 'fcmb_20240828/7564669779.csv',\n",
       " 'fcmb_20241126/156748766.csv',\n",
       " 'fcmb_20241126/7564669779.csv',\n",
       " 'fcmb_20241128/156748766.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = S3BucketHandler()\n",
    "response = handler._list_bucket_contents(\"complete-table\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b58990f-779f-40b8-81f6-47c73c62507a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bvn</th>\n",
       "      <th>dob</th>\n",
       "      <th>amount_requested</th>\n",
       "      <th>application_id</th>\n",
       "      <th>loan_tenure</th>\n",
       "      <th>loan_repayment_structure</th>\n",
       "      <th>internal_id</th>\n",
       "      <th>amount_approved</th>\n",
       "      <th>created_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>decline_reason</th>\n",
       "      <th>loan_message</th>\n",
       "      <th>file_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22207845921</td>\n",
       "      <td>28-01-1998</td>\n",
       "      <td>670000.0</td>\n",
       "      <td>7564669779</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-3a2ebb25-9ada-47d7-ba78-4faa79ebba42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-26 21:28:00</td>\n",
       "      <td>2024-11-27 11:57:00</td>\n",
       "      <td>Loan declined due to low transaction or incomp...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>fcmb_20241126/7564669779.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22150969042</td>\n",
       "      <td>30-12-1998</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>156748766</td>\n",
       "      <td>1 year</td>\n",
       "      <td>monthly</td>\n",
       "      <td>sce-4a0e8bc7-d2d8-4388-b766-219f51bc041a</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2024-11-26 21:27:00</td>\n",
       "      <td>2024-11-27 11:57:00</td>\n",
       "      <td></td>\n",
       "      <td>Completed</td>\n",
       "      <td>fcmb_20241126/156748766.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bvn         dob  amount_requested application_id loan_tenure  \\\n",
       "6  22207845921  28-01-1998          670000.0     7564669779      1 year   \n",
       "8  22150969042  30-12-1998          340000.0      156748766      1 year   \n",
       "\n",
       "  loan_repayment_structure                               internal_id  \\\n",
       "6                  monthly  sce-3a2ebb25-9ada-47d7-ba78-4faa79ebba42   \n",
       "8                  monthly  sce-4a0e8bc7-d2d8-4388-b766-219f51bc041a   \n",
       "\n",
       "   amount_approved        created_date         updated_date  \\\n",
       "6              0.0 2024-11-26 21:28:00  2024-11-27 11:57:00   \n",
       "8          90000.0 2024-11-26 21:27:00  2024-11-27 11:57:00   \n",
       "\n",
       "                                      decline_reason loan_message  \\\n",
       "6  Loan declined due to low transaction or incomp...    Completed   \n",
       "8                                                       Completed   \n",
       "\n",
       "                       file_key  \n",
       "6  fcmb_20241126/7564669779.csv  \n",
       "8   fcmb_20241126/156748766.csv  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = S3BucketHandler()\n",
    "complete_ = handler.collate_file(\"complete-table\")\n",
    "# Define a function to parse datetime strings with or without seconds \n",
    "def parse_datetime(datetime_str): \n",
    "    try: \n",
    "        return pd.to_datetime(datetime_str, format='%Y-%m-%d %H:%M:%S') \n",
    "    except ValueError: \n",
    "        return pd.to_datetime(datetime_str, format='%Y-%m-%d %H:%M') \n",
    "\n",
    "# Convert 'update_date' column to datetime \n",
    "complete_['created_date'] = complete_['created_date'].apply(parse_datetime)\n",
    "# Filter the DataFrame based on the date part of the 'update_date' column \n",
    "filtered_df = complete_[complete_['created_date'].dt.date == pd.to_datetime('2024-11-26').date()]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d32987-6383-4800-b9f4-73903a453ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e767f14-049f-46e2-a838-305a2850fd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a7afa-b5c6-4bdb-b0e6-ff2c8def0b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
